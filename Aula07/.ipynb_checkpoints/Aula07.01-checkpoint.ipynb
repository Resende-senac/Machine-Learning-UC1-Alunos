{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6d9a181-d82e-4a24-9f7c-b479183d3408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar bibliotecas \n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c930f78-97ee-4263-8971-c45b05790a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4bed6f-ae86-4943-9486-ba52cc82f28d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 59,  62,  63],\n",
       "         [ 43,  46,  45],\n",
       "         [ 50,  48,  43],\n",
       "         ...,\n",
       "         [158, 132, 108],\n",
       "         [152, 125, 102],\n",
       "         [148, 124, 103]],\n",
       "\n",
       "        [[ 16,  20,  20],\n",
       "         [  0,   0,   0],\n",
       "         [ 18,   8,   0],\n",
       "         ...,\n",
       "         [123,  88,  55],\n",
       "         [119,  83,  50],\n",
       "         [122,  87,  57]],\n",
       "\n",
       "        [[ 25,  24,  21],\n",
       "         [ 16,   7,   0],\n",
       "         [ 49,  27,   8],\n",
       "         ...,\n",
       "         [118,  84,  50],\n",
       "         [120,  84,  50],\n",
       "         [109,  73,  42]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[208, 170,  96],\n",
       "         [201, 153,  34],\n",
       "         [198, 161,  26],\n",
       "         ...,\n",
       "         [160, 133,  70],\n",
       "         [ 56,  31,   7],\n",
       "         [ 53,  34,  20]],\n",
       "\n",
       "        [[180, 139,  96],\n",
       "         [173, 123,  42],\n",
       "         [186, 144,  30],\n",
       "         ...,\n",
       "         [184, 148,  94],\n",
       "         [ 97,  62,  34],\n",
       "         [ 83,  53,  34]],\n",
       "\n",
       "        [[177, 144, 116],\n",
       "         [168, 129,  94],\n",
       "         [179, 142,  87],\n",
       "         ...,\n",
       "         [216, 184, 140],\n",
       "         [151, 118,  84],\n",
       "         [123,  92,  72]]]], dtype=uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir 1 elemento do treino. O output é 1 imagem\n",
    "x_train[0:1]\n",
    "\n",
    "# dtype=uint8: dado inteiro (int), sem sinal(u) que armazena valores de 0 a 255 usando 8 bits (2^8 =256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a445a04-6f44-4372-b3bb-8505d8330a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizar os valores dos pixels entre 0 e 1 (levando para float32 por causa dos tensores)\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35130541-2055-4a77-91cc-5f710e5ad36c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.23137255, 0.24313726, 0.24705882],\n",
       "         [0.16862746, 0.18039216, 0.1764706 ],\n",
       "         [0.19607843, 0.1882353 , 0.16862746],\n",
       "         ...,\n",
       "         [0.61960787, 0.5176471 , 0.42352942],\n",
       "         [0.59607846, 0.49019608, 0.4       ],\n",
       "         [0.5803922 , 0.4862745 , 0.40392157]],\n",
       "\n",
       "        [[0.0627451 , 0.07843138, 0.07843138],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.07058824, 0.03137255, 0.        ],\n",
       "         ...,\n",
       "         [0.48235294, 0.34509805, 0.21568628],\n",
       "         [0.46666667, 0.3254902 , 0.19607843],\n",
       "         [0.47843137, 0.34117648, 0.22352941]],\n",
       "\n",
       "        [[0.09803922, 0.09411765, 0.08235294],\n",
       "         [0.0627451 , 0.02745098, 0.        ],\n",
       "         [0.19215687, 0.10588235, 0.03137255],\n",
       "         ...,\n",
       "         [0.4627451 , 0.32941177, 0.19607843],\n",
       "         [0.47058824, 0.32941177, 0.19607843],\n",
       "         [0.42745098, 0.28627452, 0.16470589]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.8156863 , 0.6666667 , 0.3764706 ],\n",
       "         [0.7882353 , 0.6       , 0.13333334],\n",
       "         [0.7764706 , 0.6313726 , 0.10196079],\n",
       "         ...,\n",
       "         [0.627451  , 0.52156866, 0.27450982],\n",
       "         [0.21960784, 0.12156863, 0.02745098],\n",
       "         [0.20784314, 0.13333334, 0.07843138]],\n",
       "\n",
       "        [[0.7058824 , 0.54509807, 0.3764706 ],\n",
       "         [0.6784314 , 0.48235294, 0.16470589],\n",
       "         [0.7294118 , 0.5647059 , 0.11764706],\n",
       "         ...,\n",
       "         [0.72156864, 0.5803922 , 0.36862746],\n",
       "         [0.38039216, 0.24313726, 0.13333334],\n",
       "         [0.3254902 , 0.20784314, 0.13333334]],\n",
       "\n",
       "        [[0.69411767, 0.5647059 , 0.45490196],\n",
       "         [0.65882355, 0.5058824 , 0.36862746],\n",
       "         [0.7019608 , 0.5568628 , 0.34117648],\n",
       "         ...,\n",
       "         [0.84705883, 0.72156864, 0.54901963],\n",
       "         [0.5921569 , 0.4627451 , 0.32941177],\n",
       "         [0.48235294, 0.36078432, 0.28235295]]]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imprimir 1 elemento do treino. O output é 1 imagem\n",
    "x_train[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2426aa7-00b2-4985-86cc-c7d524567fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter rótulos para one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "696628c6-631c-4676-b45e-1b1644eef142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar o modelo CNN\n",
    "model = models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "819a2ad6-5354-4914-a89b-920d90d473f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\_mlUc1\\mlEnv\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Primeira camada convolucional + pooling\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b145d60e-af6d-40c6-bb53-2cb6f518ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segunda camada convolucional + pooling\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aad67d1d-82cb-4557-a181-1007ce8c7c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Terceira camada convolucional\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5fb8bd5-f726-4a6a-8ffc-d043b834f3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Achatar para passar para camadas densas\n",
    "model.add(layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "020b0830-e60e-483b-92a1-d8a8126eb944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Camadas densas finais\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))  # 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "43c6e573-944d-441d-8e77-10e665bd4a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63e428ee-fe98-4061-89ef-45d425446499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9302 - loss: 0.1974 - val_accuracy: 0.6811 - val_loss: 1.4979\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9406 - loss: 0.1714 - val_accuracy: 0.6923 - val_loss: 1.4778\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9456 - loss: 0.1563 - val_accuracy: 0.6970 - val_loss: 1.5610\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9476 - loss: 0.1485 - val_accuracy: 0.6980 - val_loss: 1.6827\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9531 - loss: 0.1320 - val_accuracy: 0.6945 - val_loss: 1.7047\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9518 - loss: 0.1355 - val_accuracy: 0.6905 - val_loss: 1.8028\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step - accuracy: 0.9592 - loss: 0.1159 - val_accuracy: 0.6914 - val_loss: 1.9165\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9534 - loss: 0.1300 - val_accuracy: 0.6924 - val_loss: 1.8878\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9525 - loss: 0.1319 - val_accuracy: 0.6925 - val_loss: 1.9273\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.9640 - loss: 0.1032 - val_accuracy: 0.6879 - val_loss: 2.0686\n"
     ]
    }
   ],
   "source": [
    "# Treinar o modelo\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "184e5a1b-2fc2-4b80-86b5-0a22f4f91c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - 4ms/step - accuracy: 0.6848 - loss: 2.0704\n",
      "Acurácia no teste: 0.68\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o modelo\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(f'Acurácia no teste: {test_acc:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ML (venv)",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
